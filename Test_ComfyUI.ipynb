{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "COMFY_HOST = \"127.0.0.1:8188\"\n",
    "\n",
    "def check_server(url, retries=500, delay=50):\n",
    "    \"\"\"\n",
    "    Check if a server is reachable via HTTP GET request\n",
    "\n",
    "    Args:\n",
    "    - url (str): The URL to check\n",
    "    - retries (int, optional): The number of times to attempt connecting to the server. Default is 50\n",
    "    - delay (int, optional): The time in milliseconds to wait between retries. Default is 500\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the server is reachable within the given number of retries, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "\n",
    "            # If the response status code is 200, the server is up and running\n",
    "            if response.status_code == 200:\n",
    "                print(f\"runpod-worker-comfy - API is reachable\")\n",
    "                return True\n",
    "        except requests.RequestException as e:\n",
    "            # If an exception occurs, the server may not be ready\n",
    "            pass\n",
    "\n",
    "        # Wait for the specified delay before retrying\n",
    "        time.sleep(delay / 1000)\n",
    "\n",
    "    print(\n",
    "        f\"runpod-worker-comfy - Failed to connect to server at {url} after {retries} attempts.\"\n",
    "    )\n",
    "    return False\n",
    "\n",
    "def queue_workflow(workflow):\n",
    "    \"\"\"\n",
    "    Queue a workflow to be processed by ComfyUI\n",
    "\n",
    "    Args:\n",
    "        workflow (dict): A dictionary containing the workflow to be processed\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response from ComfyUI after processing the workflow\n",
    "    \"\"\"\n",
    "\n",
    "    # The top level element \"prompt\" is required by ComfyUI\n",
    "    data = json.dumps({\"prompt\": workflow}).encode(\"utf-8\")\n",
    "\n",
    "    req = urllib.request.Request(f\"http://{COMFY_HOST}/prompt\", data=data)\n",
    "    return json.loads(urllib.request.urlopen(req).read())\n",
    "\n",
    "\n",
    "def get_history(prompt_id):\n",
    "    \"\"\"\n",
    "    Retrieve the history of a given prompt using its ID\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt whose history is to be retrieved\n",
    "\n",
    "    Returns:\n",
    "        dict: The history of the prompt, containing all the processing steps and results\n",
    "    \"\"\"\n",
    "    with urllib.request.urlopen(f\"http://{COMFY_HOST}/history/{prompt_id}\") as response:\n",
    "        return json.loads(response.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check if ComfyUI is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runpod-worker-comfy - API is reachable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_server(f\"http://{COMFY_HOST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Queue a workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt ID: 0967ce1f-8b38-4d20-b3c7-7ec30ed04f4c\n"
     ]
    }
   ],
   "source": [
    "# workflow = json.load(open(\"ready-to-use/Reindeer.json\"))[\"input\"][\"workflow\"]\n",
    "workflow = json.load(open(\"3I2V.json\"))\n",
    "queued_workflow = queue_workflow(workflow)\n",
    "prompt_id = queued_workflow[\"prompt_id\"]\n",
    "print(f\"Prompt ID: {prompt_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get the history of the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: {'176': {'text': ['69x832x480']}, '123': {'text': ['1x1250x1250']}, '164': {'text': ['9x624x624']}, '78': {'text': ['1x1280x720']}, '30': {'gifs': [{'filename': 'WanVideoWrapper_Skyreels-A2_00001.mp4', 'subfolder': '', 'type': 'temp', 'format': 'video/h264-mp4', 'frame_rate': 16.0, 'workflow': 'WanVideoWrapper_Skyreels-A2_00001.png', 'fullpath': '/home/money/BakstersShowcaseEndpoint/ComfyUIProdMirror/temp/WanVideoWrapper_Skyreels-A2_00001.mp4'}]}, '147': {'text': ['81x832x480']}}\n"
     ]
    }
   ],
   "source": [
    "history = get_history(prompt_id)\n",
    "if prompt_id in history and history[prompt_id].get(\"outputs\"):\n",
    "    output = history[prompt_id].get(\"outputs\")\n",
    "    print(f\"Output: {output}\")\n",
    "else:\n",
    "    print(history)\n",
    "    print(\"No output found for the given prompt ID. Maybe the workflow is still processing?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: {'9': {'images': [{'filename': 'ComfyUI_00021_.png', 'subfolder': '', 'type': 'output'}]}}\n"
     ]
    }
   ],
   "source": [
    "history = get_history(prompt_id)\n",
    "if prompt_id in history and history[prompt_id].get(\"outputs\"):\n",
    "    output = history[prompt_id].get(\"outputs\")\n",
    "    print(f\"Output: {output}\")\n",
    "else:\n",
    "    print(history)\n",
    "    print(\"No output found for the given prompt ID. Maybe the workflow is still processing?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Output Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_images(outputs, job_id, return_type):\n",
    "    \"\"\"\n",
    "    This function takes the \"outputs\" from image generation and the job ID,\n",
    "    then determines the correct way to return the image, either as a direct URL\n",
    "    to an AWS S3 bucket or as a base64 encoded string, depending on the\n",
    "    environment configuration.\n",
    "\n",
    "    Args:\n",
    "        outputs (dict): A dictionary containing the outputs from image generation,\n",
    "                        typically includes node IDs and their respective output data.\n",
    "        job_id (str): The unique identifier for the job.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the status ('success' or 'error') and the message,\n",
    "              which is either the URL to the image in the AWS S3 bucket or a base64\n",
    "              encoded string of the image. In case of error, the message details the issue.\n",
    "\n",
    "    The function works as follows:\n",
    "    - It first determines the output path for the images from an environment variable,\n",
    "      defaulting to \"/comfyui/output\" if not set.\n",
    "    - It then iterates through the outputs to find the filenames of the generated images.\n",
    "    - After confirming the existence of the image in the output folder, it checks if the\n",
    "      AWS S3 bucket is configured via the BUCKET_ENDPOINT_URL environment variable.\n",
    "    - If AWS S3 is configured, it uploads the image to the bucket and returns the URL.\n",
    "    - If AWS S3 is not configured, it checks if Cloudinary configuration is available.\n",
    "    - If Cloudinary is configured, it uploads the image to Cloudinary and returns the URL.\n",
    "    - If neither AWS S3 nor Cloudinary is configured, it encodes the image in base64 and returns the string.\n",
    "    - If the image file does not exist in the output folder, it returns an error status\n",
    "      with a message indicating the missing image file.\n",
    "    \"\"\"\n",
    "\n",
    "    # The path where ComfyUI stores the generated images\n",
    "    COMFY_OUTPUT_PATH = os.environ.get(\"COMFY_OUTPUT_PATH\", \"/comfyui/output\")\n",
    "\n",
    "    output_images = {}\n",
    "\n",
    "    for node_id, node_output in outputs.items():\n",
    "        if \"images\" in node_output:\n",
    "            for image in node_output[\"images\"]:\n",
    "                output_images = os.path.join(image[\"subfolder\"], image[\"filename\"])\n",
    "\n",
    "    print(f\"runpod-worker-comfy - image generation is done\")\n",
    "\n",
    "    # expected image output folder\n",
    "    local_image_path = f\"{COMFY_OUTPUT_PATH}/{output_images}\"\n",
    "\n",
    "    print(f\"runpod-worker-comfy - {local_image_path}\")\n",
    "\n",
    "    # The image is in the output folder\n",
    "    if os.path.exists(local_image_path):\n",
    "        if os.environ.get(\"BUCKET_ENDPOINT_URL\", False) and return_type == \"AWS_S3_URL\":\n",
    "            # URL to image in AWS S3\n",
    "            image = rp_upload.upload_image(job_id, local_image_path)\n",
    "            print(\n",
    "                \"runpod-worker-comfy - the image was generated and uploaded to AWS S3\"\n",
    "            )\n",
    "        elif (os.environ.get(\"CLOUDINARY_CLOUD_NAME\") and \n",
    "              os.environ.get(\"CLOUDINARY_API_KEY\") and \n",
    "              os.environ.get(\"CLOUDINARY_API_SECRET\")) and return_type == \"Cloudinary_URL\":\n",
    "            # Configure Cloudinary\n",
    "            cloudinary.config(\n",
    "                cloud_name=os.environ.get(\"CLOUDINARY_CLOUD_NAME\"),\n",
    "                api_key=os.environ.get(\"CLOUDINARY_API_KEY\"),\n",
    "                api_secret=os.environ.get(\"CLOUDINARY_API_SECRET\"),\n",
    "                secure=True\n",
    "            )\n",
    "            \n",
    "            # Upload to Cloudinary with a unique public_id based on job_id\n",
    "            upload_result = cloudinary.uploader.upload(\n",
    "                local_image_path,\n",
    "                resource_type=\"auto\",\n",
    "                public_id=f\"comfyui-{job_id}\"\n",
    "            )\n",
    "            \n",
    "            # Get the secure URL from the upload result\n",
    "            image = {\n",
    "                \"public_id\": f\"comfyui-{job_id}\",\n",
    "                \"secure_url\": upload_result[\"secure_url\"]\n",
    "            }\n",
    "            \n",
    "            print(\n",
    "                \"runpod-worker-comfy - the image was generated and uploaded to Cloudinary\"\n",
    "            )\n",
    "        else:\n",
    "            # base64 image\n",
    "            image = base64_encode(local_image_path)\n",
    "            print(\n",
    "                \"runpod-worker-comfy - the image was generated and converted to base64\"\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": image,\n",
    "        }\n",
    "    else:\n",
    "        print(\"runpod-worker-comfy - the image does not exist in the output folder\")\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"the image does not exist in the specified output folder: {local_image_path}\",\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
